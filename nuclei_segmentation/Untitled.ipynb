{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"The base class for dataset classes.\n",
    "    To use it, create a new class that adds functions specific to the dataset\n",
    "    you want to use. For example:\n",
    "    class CatsAndDogsDataset(Dataset):\n",
    "        def load_cats_and_dogs(self):\n",
    "            ...\n",
    "        def load_mask(self, image_id):\n",
    "            ...\n",
    "        def image_reference(self, image_id):\n",
    "            ...\n",
    "    See COCODataset and ShapesDataset as examples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, class_map=None):\n",
    "        self._image_ids = []\n",
    "        self.image_info = []\n",
    "        # Background is always the first class\n",
    "        self.class_info = [{\"source\": \"\", \"id\": 0, \"name\": \"BG\"}]\n",
    "        self.source_class_ids = {}\n",
    "\n",
    "    def add_class(self, source, class_id, class_name):\n",
    "        assert \".\" not in source, \"Source name cannot contain a dot\"\n",
    "        # Does the class exist already?\n",
    "        for info in self.class_info:\n",
    "            if info['source'] == source and info[\"id\"] == class_id:\n",
    "                # source.class_id combination already available, skip\n",
    "                return\n",
    "        # Add the class\n",
    "        self.class_info.append({\n",
    "            \"source\": source,\n",
    "            \"id\": class_id,\n",
    "            \"name\": class_name,\n",
    "        })\n",
    "\n",
    "    def add_image(self, source, image_id, path, **kwargs):\n",
    "        image_info = {\n",
    "            \"id\": image_id,\n",
    "            \"source\": source,\n",
    "            \"path\": path,\n",
    "        }\n",
    "        image_info.update(kwargs)\n",
    "        self.image_info.append(image_info)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return a link to the image in its source Website or details about\n",
    "        the image that help looking it up or debugging it.\n",
    "        Override for your dataset, but pass to this function\n",
    "        if you encounter images not in your dataset.\n",
    "        \"\"\"\n",
    "        return \"\"\n",
    "\n",
    "    def prepare(self, class_map=None):\n",
    "        \"\"\"Prepares the Dataset class for use.\n",
    "        TODO: class map is not supported yet. When done, it should handle mapping\n",
    "              classes from different datasets to the same class ID.\n",
    "        \"\"\"\n",
    "\n",
    "        def clean_name(name):\n",
    "            \"\"\"Returns a shorter version of object names for cleaner display.\"\"\"\n",
    "            return \",\".join(name.split(\",\")[:1])\n",
    "\n",
    "        # Build (or rebuild) everything else from the info dicts.\n",
    "        self.num_classes = len(self.class_info)\n",
    "        self.class_ids = np.arange(self.num_classes)\n",
    "        self.class_names = [clean_name(c[\"name\"]) for c in self.class_info]\n",
    "        self.num_images = len(self.image_info)\n",
    "        self._image_ids = np.arange(self.num_images)\n",
    "\n",
    "        self.class_from_source_map = {\"{}.{}\".format(info['source'], info['id']): id\n",
    "                                      for info, id in zip(self.class_info, self.class_ids)}\n",
    "\n",
    "        # Map sources to class_ids they support\n",
    "        self.sources = list(set([i['source'] for i in self.class_info]))\n",
    "        self.source_class_ids = {}\n",
    "        # Loop over datasets\n",
    "        for source in self.sources:\n",
    "            self.source_class_ids[source] = []\n",
    "            # Find classes that belong to this dataset\n",
    "            for i, info in enumerate(self.class_info):\n",
    "                # Include BG class in all datasets\n",
    "                if i == 0 or source == info['source']:\n",
    "                    self.source_class_ids[source].append(i)\n",
    "\n",
    "    def map_source_class_id(self, source_class_id):\n",
    "        \"\"\"Takes a source class ID and returns the int class ID assigned to it.\n",
    "        For example:\n",
    "        dataset.map_source_class_id(\"coco.12\") -> 23\n",
    "        \"\"\"\n",
    "        return self.class_from_source_map[source_class_id]\n",
    "\n",
    "    def get_source_class_id(self, class_id, source):\n",
    "        \"\"\"Map an internal class ID to the corresponding class ID in the source dataset.\"\"\"\n",
    "        info = self.class_info[class_id]\n",
    "        assert info['source'] == source\n",
    "        return info['id']\n",
    "\n",
    "    def append_data(self, class_info, image_info):\n",
    "        self.external_to_class_id = {}\n",
    "        for i, c in enumerate(self.class_info):\n",
    "            for ds, id in c[\"map\"]:\n",
    "                self.external_to_class_id[ds + str(id)] = i\n",
    "\n",
    "        # Map external image IDs to internal ones.\n",
    "        self.external_to_image_id = {}\n",
    "        for i, info in enumerate(self.image_info):\n",
    "            self.external_to_image_id[info[\"ds\"] + str(info[\"id\"])] = i\n",
    "\n",
    "    @property\n",
    "    def image_ids(self):\n",
    "        return self._image_ids\n",
    "\n",
    "    def source_image_link(self, image_id):\n",
    "        \"\"\"Returns the path or URL to the image.\n",
    "        Override this to return a URL to the image if it's availble online for easy\n",
    "        debugging.\n",
    "        \"\"\"\n",
    "        return self.image_info[image_id][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from augment_preprocess import fix_crop_transform, random_crop_transform, relabel_multi_mask\n",
    "from augment_preprocess import random_shift_scale_rotate_transform, clean_masks\n",
    "from config import Config, load_img\n",
    "import h5py\n",
    "import utils\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "normilize  =transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                     std=[0.229, 0.224, 0.225],inplace = True)\n",
    "\n",
    "class NucleiDataset(Dataset):\n",
    "\n",
    "    def load_shapes(self, id_list, train_path,mode):\n",
    "        \"\"\"initialize the class with dataset info.\n",
    "        \"\"\"\n",
    "        self.transform = transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "        normilize])\n",
    "                           \n",
    "        self.config = Config()\n",
    "        if mode == 'train':\n",
    "            self.augment = True\n",
    "        else:\n",
    "            self.augment = False\n",
    "        # Add classes\n",
    "        self.add_class('images', 1, \"nucleus\")\n",
    "        self.train_path = train_path\n",
    "        self.imgs = id_list\n",
    "        # Add images\n",
    "        for i, id_ in enumerate(id_list):\n",
    "            self.add_image('images', image_id=i, path=None,\n",
    "                           img_name=id_)\n",
    "            \n",
    "            \n",
    "    def load_image(self, image_id, color):\n",
    "        \"\"\"Load image from directory\n",
    "        \"\"\"\n",
    "\n",
    "        info = self.image_info[image_id]\n",
    "        path = self.train_path + info['img_name'] + \\\n",
    "            '/images/' + info['img_name'] + '.png'\n",
    "\n",
    "        img = load_img(path, color=color)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the images data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == 'images':\n",
    "            return info['images']\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for images of the given image ID.\n",
    "        \"\"\"\n",
    "\n",
    "        info = self.image_info[image_id]\n",
    "\n",
    "        path = self.train_path + info['img_name'] + \\\n",
    "            '/masks/' + info['img_name'] + '.h5'\n",
    "        if os.path.exists(path):\n",
    "            # For faster data loading run augment_preprocess.py file first\n",
    "            # That should save masks in a single h5 file\n",
    "            with h5py.File(path, \"r\") as hf:\n",
    "                mask = hf[\"arr\"][()]\n",
    "        else:\n",
    "            path = self.train_path + info['img_name']\n",
    "            mask = []\n",
    "            for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "                if 'png' in mask_file:\n",
    "                    mask_ = cv2.imread(path + '/masks/' + mask_file, 0)\n",
    "                    mask_ = np.where(mask_ > 128, 1, 0)\n",
    "                    # Fill holes in the mask\n",
    "                    mask_ = binary_fill_holes(mask_).astype(np.int32)\n",
    "                    # Add mask only if its area is larger than one pixel\n",
    "                    if np.sum(mask_) >= 1:\n",
    "                        mask.append(np.squeeze(mask_))\n",
    "\n",
    "            mask = np.stack(mask, axis=-1)\n",
    "            mask = mask.astype(np.uint8)\n",
    "\n",
    "        # Class ids: all ones since all are foreground objects\n",
    "        class_ids = np.ones(mask.shape[2])\n",
    "\n",
    "        return mask.astype(np.uint8), class_ids.astype(np.int8)\n",
    "\n",
    "    def __getitem__(self, image_id):\n",
    "        # load images ad masks\n",
    "        # Load image and mask\n",
    "        image = self.load_image(image_id, self.config.IMAGE_COLOR)\n",
    "        masks, class_ids = self.load_mask(image_id)\n",
    "        temp_image, temp_mask = random_crop_transform(image, masks, 512, 512)\n",
    "        keep_ind = np.where(np.sum(temp_mask, axis=(0, 1)) > 0)[0]\n",
    "        if len(keep_ind) > 0:\n",
    "            image = temp_image.copy()\n",
    "            masks = temp_mask[:,:,keep_ind]\n",
    "\n",
    "        \n",
    "\n",
    "        # Random scaling\n",
    "        if self.augment and self.config.SCALE and np.random.rand() < 0.9:\n",
    "            H, W = masks.shape[:2]\n",
    "             #multi_mask = np.sum(mask*np.arange(1, mask.shape[-1]+1), axis=-1)\n",
    "            temp_image, temp_mask = random_shift_scale_rotate_transform(image.copy(), masks.copy(),\n",
    "                                                                         shift_limit=[-0.1,0.1], scale_limit=[1/1.5, 1.5],\n",
    "                                                                         rotate_limit=[-15, 15])\n",
    "            temp_mask = temp_mask if len(temp_mask.shape) ==3 else np.expand_dims(temp_mask,axis = 2)\n",
    "             #temp_mask = np.repeat(multi_mask[:, :, np.newaxis], multi_mask.max(), axis=-1)\n",
    "             #temp_mask = np.equal(temp_mask, np.ones_like(temp_mask)*np.arange(1, multi_mask.max()+1)).astype(np.uint8)\n",
    "\n",
    "            keep_ind = np.where(np.sum(temp_mask, axis=(0, 1)) > 0)[0]\n",
    "            if len(keep_ind) > 0:\n",
    "                image = temp_image\n",
    "                masks = temp_mask[:,:,keep_ind]\n",
    "\n",
    "         #print(masks.shape)\n",
    "        # Random cropping\n",
    "        if (masks.shape[2] > 80) or (self.augment and self.config.CROP and np.random.rand() < 0.5):\n",
    "\n",
    "            height = self.config.CROP_SHAPE[1]\n",
    "            width = self.config.CROP_SHAPE[0]\n",
    "\n",
    "            temp_image, temp_mask = random_crop_transform(image, masks, height, width)\n",
    "            keep_ind = np.where(np.sum(temp_mask, axis=(0, 1)) > 0)[0]\n",
    "            if len(keep_ind) > 0:\n",
    "                image = temp_image.copy()\n",
    "                masks = temp_mask[:,:,keep_ind]\n",
    "\n",
    "        shape = image.shape\n",
    "        image, window, scale, padding = utils.resize_image(\n",
    "            image,\n",
    "            min_dim=self.config.IMAGE_MIN_DIM,\n",
    "            max_dim=self.config.IMAGE_MAX_DIM,\n",
    "            padding=self.config.IMAGE_PADDING)\n",
    "        masks = utils.resize_mask(masks, scale, padding)\n",
    "        \n",
    "    \n",
    "        \n",
    "        # Random horizontal and vertical flips.\n",
    "        if self.augment:\n",
    "\n",
    "            # horizontal\n",
    "            if np.random.rand() < 0.5:\n",
    "                image = np.fliplr(image)\n",
    "                masks = np.fliplr(masks)\n",
    "            # Vertical\n",
    "            if np.random.rand() < 0.5:\n",
    "                image = np.flipud(image)\n",
    "                masks = np.flipud(masks)\n",
    "\n",
    "            # Random 90 degree rotation\n",
    "            if np.random.rand() < 0.5:\n",
    "                angle = np.random.choice([1, -1])\n",
    "                image = np.rot90(image, k=angle, axes=(0, 1))\n",
    "                masks = np.rot90(masks, k=angle, axes=(0, 1))\n",
    "\n",
    "            # # Random Gaussian blur\n",
    "            # if random.randint(0, 1):\n",
    "            #     sigma = np.random.uniform(1.5,2.5)\n",
    "            #     image = cv2.GaussianBlur(image, (33, 33), sigma)\n",
    "        \n",
    "        \n",
    "    \n",
    "        keep_ind = np.where(np.sum(masks, axis=(0, 1)) > 0)[0]\n",
    "        if len(keep_ind) > 0:\n",
    "            masks = masks[:,:,keep_ind]\n",
    "         #image =  np.swapaxes(np.swapaxes(image,1,2),0,1)\n",
    "        \n",
    "        masks = masks.transpose((2, 0, 1))\n",
    "         # get bounding box coordinates for each mask\n",
    "        num_objs = masks.shape[0]\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            \n",
    "        print(image_id,masks.shape,image.shape)\n",
    "        # convert everything into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        image  = self.transform((image/image.max()).astype(np.float32))\n",
    "        image_id = torch.tensor([image_id])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "       \n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_split(train_path,classes_csv , seed=10, test_size=0.1):\n",
    "\n",
    "    \"\"\"\n",
    "    Split the dataset into train and validation sets.\n",
    "    External data and mosaics are directly appended to training set.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import pandas as pd \n",
    "    \n",
    "    image_ids = list(\n",
    "        filter(lambda x: ('mosaic' not in x) and ('TCGA' not in x), os.listdir(train_path)))\n",
    "    mosaic_ids = list(filter(lambda x: 'mosaic' in x, os.listdir(train_path)))\n",
    "    external_ids = list(filter(lambda x: 'TCGA' in x, os.listdir(train_path)))\n",
    "\n",
    "    # Load and preprocess the dataset with train image modalities\n",
    "    df = pd.read_csv(classes_csv)\n",
    "    df['labels'] = df['foreground'].astype(str) + df['background']\n",
    "    df['filename'] = df['filename'].apply(lambda x: x[:-4])\n",
    "    df = df.set_index('filename')\n",
    "    df = df.loc[image_ids]\n",
    "    df = df.loc[df.background == 'black']\n",
    "    # Split training set based on provided image modalities\n",
    "    # This ensures that model validates on all image modalities.\n",
    "    train_list, val_list = train_test_split(df.index, test_size=test_size,\n",
    "                                            random_state=seed, stratify=df['labels'])\n",
    "\n",
    "    # Add external data and mos ids to training list\n",
    "    train_list = list(train_list)\n",
    "    val_list = list(val_list)\n",
    "\n",
    "    return train_list, val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "from config import DATASET_PATH\n",
    "train_path = op.join(DATASET_PATH,'stage1_train/')\n",
    "classes_csv = op.join(DATASET_PATH,'classes.csv')\n",
    "\n",
    "# Split the training set into training and validation\n",
    "train_list, val_list = train_validation_split(\n",
    "    train_path,classes_csv , seed=11, test_size=0.1)\n",
    "\n",
    "# initialize training dataset\n",
    "dataset_train = NucleiDataset()\n",
    "dataset_train.load_shapes(train_list, train_path,'train')\n",
    "dataset_train.prepare()\n",
    "\n",
    "# initialize validation dataset\n",
    "dataset_val = NucleiDataset()\n",
    "dataset_val.load_shapes(val_list, train_path,'val')\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 (21, 1024, 1024) (1024, 1024, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2bfa7838e10>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image,target =dataset_train.__getitem__(3)\n",
    "plt.imshow(image.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3368, -1.2367, -1.0119])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2bf94b8c2b0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(target['masks'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "import torch\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (20, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [  0/491]  eta: 0:07:34  lr: 0.000002  loss: 7.0142 (7.0142)  loss_classifier: 0.6326 (0.6326)  loss_box_reg: 0.5451 (0.5451)  loss_mask: 4.9485 (4.9485)  loss_objectness: 0.8089 (0.8089)  loss_rpn_box_reg: 0.0791 (0.0791)  time: 0.9262  data: 0.5621  max mem: 1920\n",
      "1 (19, 1024, 1024) (1024, 1024, 3)\n",
      "2 (89, 1024, 1024) (1024, 1024, 3)\n",
      "3 (20, 1024, 1024) (1024, 1024, 3)\n",
      "4 (9, 1024, 1024) (1024, 1024, 3)\n",
      "5 (14, 1024, 1024) (1024, 1024, 3)\n",
      "6 (6, 1024, 1024) (1024, 1024, 3)\n",
      "7 (21, 1024, 1024) (1024, 1024, 3)\n",
      "8 (9, 1024, 1024) (1024, 1024, 3)\n",
      "9 (48, 1024, 1024) (1024, 1024, 3)\n",
      "10 (19, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [ 10/491]  eta: 0:08:35  lr: 0.000012  loss: 6.4504 (6.8507)  loss_classifier: 0.5815 (0.5846)  loss_box_reg: 0.5451 (0.5264)  loss_mask: 3.9289 (3.9325)  loss_objectness: 1.2320 (1.6392)  loss_rpn_box_reg: 0.1129 (0.1680)  time: 1.0714  data: 0.7534  max mem: 2316\n",
      "11 (15, 1024, 1024) (1024, 1024, 3)\n",
      "12 (28, 1024, 1024) (1024, 1024, 3)\n",
      "13 (25, 1024, 1024) (1024, 1024, 3)\n",
      "14 (3, 1024, 1024) (1024, 1024, 3)\n",
      "15 (18, 1024, 1024) (1024, 1024, 3)\n",
      "16 (144, 1024, 1024) (1024, 1024, 3)\n",
      "17 (22, 1024, 1024) (1024, 1024, 3)\n",
      "18 (49, 1024, 1024) (1024, 1024, 3)\n",
      "19 (12, 1024, 1024) (1024, 1024, 3)\n",
      "20 (25, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [ 20/491]  eta: 0:17:31  lr: 0.000022  loss: 5.6571 (6.0139)  loss_classifier: 0.5717 (0.5672)  loss_box_reg: 0.5150 (0.4922)  loss_mask: 3.0629 (2.9261)  loss_objectness: 1.3536 (1.8339)  loss_rpn_box_reg: 0.1489 (0.1944)  time: 2.2969  data: 1.9854  max mem: 2652\n",
      "21 (26, 1024, 1024) (1024, 1024, 3)\n",
      "22 (21, 1024, 1024) (1024, 1024, 3)\n",
      "23 (1, 1024, 1024) (1024, 1024, 3)\n",
      "24 (17, 1024, 1024) (1024, 1024, 3)\n",
      "25 (7, 1024, 1024) (1024, 1024, 3)\n",
      "26 (47, 1024, 1024) (1024, 1024, 3)\n",
      "27 (20, 1024, 1024) (1024, 1024, 3)\n",
      "28 (17, 1024, 1024) (1024, 1024, 3)\n",
      "29 (21, 1024, 1024) (1024, 1024, 3)\n",
      "30 (17, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [ 30/491]  eta: 0:13:43  lr: 0.000032  loss: 3.5775 (5.1288)  loss_classifier: 0.5239 (0.5448)  loss_box_reg: 0.5238 (0.4974)  loss_mask: 1.0413 (2.2289)  loss_objectness: 1.3238 (1.6362)  loss_rpn_box_reg: 0.2234 (0.2215)  time: 2.1800  data: 1.8710  max mem: 2652\n",
      "31 (28, 1024, 1024) (1024, 1024, 3)\n",
      "32 (19, 1024, 1024) (1024, 1024, 3)\n",
      "33 (8, 1024, 1024) (1024, 1024, 3)\n",
      "34 (4, 1024, 1024) (1024, 1024, 3)\n",
      "35 (49, 1024, 1024) (1024, 1024, 3)\n",
      "36 (10, 1024, 1024) (1024, 1024, 3)\n",
      "37 (16, 1024, 1024) (1024, 1024, 3)\n",
      "38 (5, 1024, 1024) (1024, 1024, 3)\n",
      "39 (54, 1024, 1024) (1024, 1024, 3)\n",
      "40 (41, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [ 40/491]  eta: 0:13:18  lr: 0.000042  loss: 2.2369 (4.3780)  loss_classifier: 0.4973 (0.5261)  loss_box_reg: 0.5397 (0.4940)  loss_mask: 0.6133 (1.8328)  loss_objectness: 0.5154 (1.3257)  loss_rpn_box_reg: 0.1171 (0.1996)  time: 1.2885  data: 0.9789  max mem: 2652\n",
      "41 (110, 1024, 1024) (1024, 1024, 3)\n",
      "42 (7, 1024, 1024) (1024, 1024, 3)\n",
      "43 (33, 1024, 1024) (1024, 1024, 3)\n",
      "44 (12, 1024, 1024) (1024, 1024, 3)\n",
      "45 (7, 1024, 1024) (1024, 1024, 3)\n",
      "46 (31, 1024, 1024) (1024, 1024, 3)\n",
      "47 (73, 1024, 1024) (1024, 1024, 3)\n",
      "48 (115, 1024, 1024) (1024, 1024, 3)\n",
      "49 (53, 1024, 1024) (1024, 1024, 3)\n",
      "50 (72, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [ 50/491]  eta: 0:19:46  lr: 0.000052  loss: 1.9811 (3.9187)  loss_classifier: 0.4545 (0.5124)  loss_box_reg: 0.4974 (0.4875)  loss_mask: 0.5405 (1.5712)  loss_objectness: 0.3296 (1.1308)  loss_rpn_box_reg: 0.1864 (0.2167)  time: 4.0889  data: 3.7642  max mem: 2652\n",
      "51 (72, 1024, 1024) (1024, 1024, 3)\n",
      "52 (18, 1024, 1024) (1024, 1024, 3)\n",
      "53 (5, 1024, 1024) (1024, 1024, 3)\n",
      "54 (65, 1024, 1024) (1024, 1024, 3)\n",
      "55 (74, 1024, 1024) (1024, 1024, 3)\n",
      "56 (19, 1024, 1024) (1024, 1024, 3)\n",
      "57 (10, 1024, 1024) (1024, 1024, 3)\n",
      "58 (23, 1024, 1024) (1024, 1024, 3)\n",
      "59 (143, 1024, 1024) (1024, 1024, 3)\n",
      "60 (28, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [ 60/491]  eta: 0:23:09  lr: 0.000063  loss: 2.1083 (3.6292)  loss_classifier: 0.4399 (0.4984)  loss_box_reg: 0.4278 (0.4777)  loss_mask: 0.4400 (1.3791)  loss_objectness: 0.4005 (1.0216)  loss_rpn_box_reg: 0.3411 (0.2525)  time: 6.2040  data: 5.8684  max mem: 2652\n",
      "61 (15, 1024, 1024) (1024, 1024, 3)\n",
      "62 (8, 1024, 1024) (1024, 1024, 3)\n",
      "63 (32, 1024, 1024) (1024, 1024, 3)\n",
      "64 (52, 1024, 1024) (1024, 1024, 3)\n",
      "65 (4, 1024, 1024) (1024, 1024, 3)\n",
      "66 (55, 1024, 1024) (1024, 1024, 3)\n",
      "67 (11, 1024, 1024) (1024, 1024, 3)\n",
      "68 (106, 1024, 1024) (1024, 1024, 3)\n",
      "69 (36, 1024, 1024) (1024, 1024, 3)\n",
      "70 (16, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [ 70/491]  eta: 0:23:03  lr: 0.000073  loss: 1.8042 (3.3615)  loss_classifier: 0.4123 (0.4841)  loss_box_reg: 0.4729 (0.4731)  loss_mask: 0.3926 (1.2373)  loss_objectness: 0.2837 (0.9127)  loss_rpn_box_reg: 0.2516 (0.2542)  time: 4.8079  data: 4.4772  max mem: 2652\n",
      "71 (3, 1024, 1024) (1024, 1024, 3)\n",
      "72 (1, 1024, 1024) (1024, 1024, 3)\n",
      "73 (9, 1024, 1024) (1024, 1024, 3)\n",
      "74 (21, 1024, 1024) (1024, 1024, 3)\n",
      "75 (26, 1024, 1024) (1024, 1024, 3)\n",
      "76 (31, 1024, 1024) (1024, 1024, 3)\n",
      "77 (4, 1024, 1024) (1024, 1024, 3)\n",
      "78 (56, 1024, 1024) (1024, 1024, 3)\n",
      "79 (21, 1024, 1024) (1024, 1024, 3)\n",
      "80 (9, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [ 80/491]  eta: 0:20:28  lr: 0.000083  loss: 1.5917 (3.1109)  loss_classifier: 0.3988 (0.4664)  loss_box_reg: 0.4484 (0.4625)  loss_mask: 0.3331 (1.1256)  loss_objectness: 0.1582 (0.8187)  loss_rpn_box_reg: 0.1555 (0.2378)  time: 2.2676  data: 1.9524  max mem: 2652\n",
      "81 (6, 1024, 1024) (1024, 1024, 3)\n",
      "82 (27, 1024, 1024) (1024, 1024, 3)\n",
      "83 (17, 1024, 1024) (1024, 1024, 3)\n",
      "84 (29, 1024, 1024) (1024, 1024, 3)\n",
      "85 (14, 1024, 1024) (1024, 1024, 3)\n",
      "86 (83, 1024, 1024) (1024, 1024, 3)\n",
      "87 (32, 1024, 1024) (1024, 1024, 3)\n",
      "88 (101, 1024, 1024) (1024, 1024, 3)\n",
      "89 (42, 1024, 1024) (1024, 1024, 3)\n",
      "90 (31, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [ 90/491]  eta: 0:19:49  lr: 0.000093  loss: 1.4648 (2.9474)  loss_classifier: 0.3384 (0.4541)  loss_box_reg: 0.4249 (0.4598)  loss_mask: 0.2995 (1.0352)  loss_objectness: 0.1533 (0.7568)  loss_rpn_box_reg: 0.1484 (0.2414)  time: 1.8281  data: 1.5150  max mem: 2652\n",
      "91 (18, 1024, 1024) (1024, 1024, 3)\n",
      "92 (19, 1024, 1024) (1024, 1024, 3)\n",
      "93 (11, 1024, 1024) (1024, 1024, 3)\n",
      "94 (109, 1024, 1024) (1024, 1024, 3)\n",
      "95 (7, 1024, 1024) (1024, 1024, 3)\n",
      "96 (7, 1024, 1024) (1024, 1024, 3)\n",
      "97 (69, 1024, 1024) (1024, 1024, 3)\n",
      "98 (9, 1024, 1024) (1024, 1024, 3)\n",
      "99 (47, 1024, 1024) (1024, 1024, 3)\n",
      "100 (16, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [100/491]  eta: 0:18:11  lr: 0.000103  loss: 1.4180 (2.8075)  loss_classifier: 0.3336 (0.4406)  loss_box_reg: 0.4249 (0.4581)  loss_mask: 0.2732 (0.9623)  loss_objectness: 0.1002 (0.6980)  loss_rpn_box_reg: 0.1967 (0.2486)  time: 1.9901  data: 1.6685  max mem: 2652\n",
      "101 (16, 1024, 1024) (1024, 1024, 3)\n",
      "102 (53, 1024, 1024) (1024, 1024, 3)\n",
      "103 (17, 1024, 1024) (1024, 1024, 3)\n",
      "104 (14, 1024, 1024) (1024, 1024, 3)\n",
      "105 (20, 1024, 1024) (1024, 1024, 3)\n",
      "106 (16, 1024, 1024) (1024, 1024, 3)\n",
      "107 (9, 1024, 1024) (1024, 1024, 3)\n",
      "108 (8, 1024, 1024) (1024, 1024, 3)\n",
      "109 (6, 1024, 1024) (1024, 1024, 3)\n",
      "110 (108, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [110/491]  eta: 0:17:42  lr: 0.000114  loss: 1.2149 (2.6706)  loss_classifier: 0.3067 (0.4279)  loss_box_reg: 0.4319 (0.4548)  loss_mask: 0.2770 (0.9046)  loss_objectness: 0.0960 (0.6443)  loss_rpn_box_reg: 0.1113 (0.2390)  time: 1.9766  data: 1.6653  max mem: 2652\n",
      "111 (26, 1024, 1024) (1024, 1024, 3)\n",
      "112 (20, 1024, 1024) (1024, 1024, 3)\n",
      "113 (80, 1024, 1024) (1024, 1024, 3)\n",
      "114 (21, 1024, 1024) (1024, 1024, 3)\n",
      "115 (80, 1024, 1024) (1024, 1024, 3)\n",
      "116 (28, 1024, 1024) (1024, 1024, 3)\n",
      "117 (11, 1024, 1024) (1024, 1024, 3)\n",
      "118 (18, 1024, 1024) (1024, 1024, 3)\n",
      "119 (52, 1024, 1024) (1024, 1024, 3)\n",
      "120 (12, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [120/491]  eta: 0:17:48  lr: 0.000124  loss: 1.2317 (2.5706)  loss_classifier: 0.3067 (0.4206)  loss_box_reg: 0.4268 (0.4526)  loss_mask: 0.2780 (0.8554)  loss_objectness: 0.1039 (0.6041)  loss_rpn_box_reg: 0.1181 (0.2380)  time: 3.3325  data: 3.0165  max mem: 2652\n",
      "121 (23, 1024, 1024) (1024, 1024, 3)\n",
      "122 (24, 1024, 1024) (1024, 1024, 3)\n",
      "123 (19, 1024, 1024) (1024, 1024, 3)\n",
      "124 (4, 1024, 1024) (1024, 1024, 3)\n",
      "125 (28, 1024, 1024) (1024, 1024, 3)\n",
      "126 (29, 1024, 1024) (1024, 1024, 3)\n",
      "127 (23, 1024, 1024) (1024, 1024, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 (20, 1024, 1024) (1024, 1024, 3)\n",
      "129 (61, 1024, 1024) (1024, 1024, 3)\n",
      "130 (5, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [130/491]  eta: 0:16:52  lr: 0.000134  loss: 1.2274 (2.4653)  loss_classifier: 0.2884 (0.4086)  loss_box_reg: 0.4225 (0.4474)  loss_mask: 0.2497 (0.8121)  loss_objectness: 0.1086 (0.5648)  loss_rpn_box_reg: 0.1501 (0.2325)  time: 2.9087  data: 2.5872  max mem: 2652\n",
      "131 (65, 1024, 1024) (1024, 1024, 3)\n",
      "132 (28, 1024, 1024) (1024, 1024, 3)\n",
      "133 (40, 1024, 1024) (1024, 1024, 3)\n",
      "134 (10, 1024, 1024) (1024, 1024, 3)\n",
      "135 (76, 1024, 1024) (1024, 1024, 3)\n",
      "136 (1, 1024, 1024) (1024, 1024, 3)\n",
      "137 (9, 1024, 1024) (1024, 1024, 3)\n",
      "138 (48, 1024, 1024) (1024, 1024, 3)\n",
      "139 (17, 1024, 1024) (1024, 1024, 3)\n",
      "140 (9, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [140/491]  eta: 0:15:45  lr: 0.000144  loss: 1.2206 (2.3816)  loss_classifier: 0.2546 (0.3969)  loss_box_reg: 0.3623 (0.4376)  loss_mask: 0.2485 (0.7814)  loss_objectness: 0.0605 (0.5382)  loss_rpn_box_reg: 0.1320 (0.2275)  time: 1.5729  data: 1.2564  max mem: 2652\n",
      "141 (10, 1024, 1024) (1024, 1024, 3)\n",
      "142 (44, 1024, 1024) (1024, 1024, 3)\n",
      "143 (7, 1024, 1024) (1024, 1024, 3)\n",
      "144 (2, 1024, 1024) (1024, 1024, 3)\n",
      "145 (8, 1024, 1024) (1024, 1024, 3)\n",
      "146 (24, 1024, 1024) (1024, 1024, 3)\n",
      "147 (24, 1024, 1024) (1024, 1024, 3)\n",
      "148 (42, 1024, 1024) (1024, 1024, 3)\n",
      "149 (2, 1024, 1024) (1024, 1024, 3)\n",
      "150 (94, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [150/491]  eta: 0:15:07  lr: 0.000154  loss: 1.2507 (2.2981)  loss_classifier: 0.2031 (0.3870)  loss_box_reg: 0.3280 (0.4302)  loss_mask: 0.2606 (0.7500)  loss_objectness: 0.0614 (0.5086)  loss_rpn_box_reg: 0.1286 (0.2223)  time: 1.7231  data: 1.4058  max mem: 2652\n",
      "151 (40, 1024, 1024) (1024, 1024, 3)\n",
      "152 (9, 1024, 1024) (1024, 1024, 3)\n",
      "153 (19, 1024, 1024) (1024, 1024, 3)\n",
      "154 (30, 1024, 1024) (1024, 1024, 3)\n",
      "155 (43, 1024, 1024) (1024, 1024, 3)\n",
      "156 (28, 1024, 1024) (1024, 1024, 3)\n",
      "157 (89, 1024, 1024) (1024, 1024, 3)\n",
      "158 (18, 1024, 1024) (1024, 1024, 3)\n",
      "159 (1, 1024, 1024) (1024, 1024, 3)\n",
      "160 (21, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [160/491]  eta: 0:14:12  lr: 0.000165  loss: 1.2696 (2.2417)  loss_classifier: 0.2854 (0.3825)  loss_box_reg: 0.3298 (0.4223)  loss_mask: 0.2606 (0.7243)  loss_objectness: 0.1426 (0.4924)  loss_rpn_box_reg: 0.1906 (0.2201)  time: 1.7252  data: 1.4014  max mem: 2652\n",
      "161 (21, 1024, 1024) (1024, 1024, 3)\n",
      "162 (59, 1024, 1024) (1024, 1024, 3)\n",
      "163 (6, 1024, 1024) (1024, 1024, 3)\n",
      "164 (22, 1024, 1024) (1024, 1024, 3)\n",
      "165 (42, 1024, 1024) (1024, 1024, 3)\n",
      "166 (6, 1024, 1024) (1024, 1024, 3)\n",
      "167 (9, 1024, 1024) (1024, 1024, 3)\n",
      "168 (21, 1024, 1024) (1024, 1024, 3)\n",
      "169 (63, 1024, 1024) (1024, 1024, 3)\n",
      "170 (34, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [170/491]  eta: 0:13:36  lr: 0.000175  loss: 1.2174 (2.1818)  loss_classifier: 0.2719 (0.3737)  loss_box_reg: 0.3089 (0.4148)  loss_mask: 0.2529 (0.6971)  loss_objectness: 0.1426 (0.4712)  loss_rpn_box_reg: 0.1919 (0.2251)  time: 1.6482  data: 1.3190  max mem: 2652\n",
      "171 (30, 1024, 1024) (1024, 1024, 3)\n",
      "172 (98, 1024, 1024) (1024, 1024, 3)\n",
      "173 (5, 1024, 1024) (1024, 1024, 3)\n",
      "174 (41, 1024, 1024) (1024, 1024, 3)\n",
      "175 (8, 1024, 1024) (1024, 1024, 3)\n",
      "176 (11, 1024, 1024) (1024, 1024, 3)\n",
      "177 (14, 1024, 1024) (1024, 1024, 3)\n",
      "178 (46, 1024, 1024) (1024, 1024, 3)\n",
      "179 (31, 1024, 1024) (1024, 1024, 3)\n",
      "180 (30, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [180/491]  eta: 0:13:15  lr: 0.000185  loss: 1.1953 (2.1307)  loss_classifier: 0.2324 (0.3680)  loss_box_reg: 0.2578 (0.4067)  loss_mask: 0.2582 (0.6755)  loss_objectness: 0.1102 (0.4544)  loss_rpn_box_reg: 0.2169 (0.2262)  time: 2.4259  data: 2.1002  max mem: 2652\n",
      "181 (135, 1024, 1024) (1024, 1024, 3)\n",
      "182 (10, 1024, 1024) (1024, 1024, 3)\n",
      "183 (11, 1024, 1024) (1024, 1024, 3)\n",
      "184 (26, 1024, 1024) (1024, 1024, 3)\n",
      "185 (21, 1024, 1024) (1024, 1024, 3)\n",
      "186 (50, 1024, 1024) (1024, 1024, 3)\n",
      "187 (93, 1024, 1024) (1024, 1024, 3)\n",
      "188 (12, 1024, 1024) (1024, 1024, 3)\n",
      "189 (72, 1024, 1024) (1024, 1024, 3)\n",
      "190 (2, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [190/491]  eta: 0:13:25  lr: 0.000195  loss: 1.2122 (2.0749)  loss_classifier: 0.2398 (0.3614)  loss_box_reg: 0.2557 (0.3985)  loss_mask: 0.2895 (0.6557)  loss_objectness: 0.1016 (0.4366)  loss_rpn_box_reg: 0.2124 (0.2226)  time: 3.7913  data: 3.4651  max mem: 2652\n",
      "191 (16, 1024, 1024) (1024, 1024, 3)\n",
      "192 (24, 1024, 1024) (1024, 1024, 3)\n",
      "193 (15, 1024, 1024) (1024, 1024, 3)\n",
      "194 (40, 1024, 1024) (1024, 1024, 3)\n",
      "195 (10, 1024, 1024) (1024, 1024, 3)\n",
      "196 (6, 1024, 1024) (1024, 1024, 3)\n",
      "197 (18, 1024, 1024) (1024, 1024, 3)\n",
      "198 (26, 1024, 1024) (1024, 1024, 3)\n",
      "199 (9, 1024, 1024) (1024, 1024, 3)\n",
      "200 (21, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [200/491]  eta: 0:12:32  lr: 0.000205  loss: 0.9597 (2.0197)  loss_classifier: 0.2117 (0.3568)  loss_box_reg: 0.2637 (0.3922)  loss_mask: 0.2315 (0.6356)  loss_objectness: 0.0827 (0.4185)  loss_rpn_box_reg: 0.0858 (0.2166)  time: 2.8303  data: 2.5068  max mem: 2652\n",
      "201 (32, 1024, 1024) (1024, 1024, 3)\n",
      "202 (52, 1024, 1024) (1024, 1024, 3)\n",
      "203 (14, 1024, 1024) (1024, 1024, 3)\n",
      "204 (47, 1024, 1024) (1024, 1024, 3)\n",
      "205 (33, 1024, 1024) (1024, 1024, 3)\n",
      "206 (5, 1024, 1024) (1024, 1024, 3)\n",
      "207 (34, 1024, 1024) (1024, 1024, 3)\n",
      "208 (13, 1024, 1024) (1024, 1024, 3)\n",
      "209 (83, 1024, 1024) (1024, 1024, 3)\n",
      "210 (5, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [210/491]  eta: 0:11:58  lr: 0.000216  loss: 0.8259 (1.9765)  loss_classifier: 0.1985 (0.3497)  loss_box_reg: 0.2332 (0.3836)  loss_mask: 0.2286 (0.6178)  loss_objectness: 0.0679 (0.4065)  loss_rpn_box_reg: 0.1150 (0.2189)  time: 1.4262  data: 1.1084  max mem: 2652\n",
      "211 (40, 1024, 1024) (1024, 1024, 3)\n",
      "212 (10, 1024, 1024) (1024, 1024, 3)\n",
      "213 (21, 1024, 1024) (1024, 1024, 3)\n",
      "214 (55, 1024, 1024) (1024, 1024, 3)\n",
      "215 (2, 1024, 1024) (1024, 1024, 3)\n",
      "216 (16, 1024, 1024) (1024, 1024, 3)\n",
      "217 (37, 1024, 1024) (1024, 1024, 3)\n",
      "218 (32, 1024, 1024) (1024, 1024, 3)\n",
      "219 (86, 1024, 1024) (1024, 1024, 3)\n",
      "220 (156, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [220/491]  eta: 0:12:08  lr: 0.000226  loss: 0.8969 (1.9344)  loss_classifier: 0.1968 (0.3436)  loss_box_reg: 0.1820 (0.3752)  loss_mask: 0.2227 (0.5999)  loss_objectness: 0.1070 (0.3946)  loss_rpn_box_reg: 0.1743 (0.2210)  time: 3.7404  data: 3.4140  max mem: 2724\n",
      "221 (23, 1024, 1024) (1024, 1024, 3)\n",
      "222 (18, 1024, 1024) (1024, 1024, 3)\n",
      "223 (28, 1024, 1024) (1024, 1024, 3)\n",
      "224 (20, 1024, 1024) (1024, 1024, 3)\n",
      "225 (13, 1024, 1024) (1024, 1024, 3)\n",
      "226 (7, 1024, 1024) (1024, 1024, 3)\n",
      "227 (47, 1024, 1024) (1024, 1024, 3)\n",
      "228 (29, 1024, 1024) (1024, 1024, 3)\n",
      "229 (20, 1024, 1024) (1024, 1024, 3)\n",
      "230 (9, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [230/491]  eta: 0:11:28  lr: 0.000236  loss: 0.7777 (1.8901)  loss_classifier: 0.1909 (0.3385)  loss_box_reg: 0.1852 (0.3678)  loss_mask: 0.1923 (0.5839)  loss_objectness: 0.0722 (0.3819)  loss_rpn_box_reg: 0.1357 (0.2180)  time: 3.4952  data: 3.1642  max mem: 2724\n",
      "231 (22, 1024, 1024) (1024, 1024, 3)\n",
      "232 (130, 1024, 1024) (1024, 1024, 3)\n",
      "233 (16, 1024, 1024) (1024, 1024, 3)\n",
      "234 (38, 1024, 1024) (1024, 1024, 3)\n",
      "235 (3, 1024, 1024) (1024, 1024, 3)\n",
      "236 (6, 1024, 1024) (1024, 1024, 3)\n",
      "237 (6, 1024, 1024) (1024, 1024, 3)\n",
      "238 (14, 1024, 1024) (1024, 1024, 3)\n",
      "239 (31, 1024, 1024) (1024, 1024, 3)\n",
      "240 (196, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [240/491]  eta: 0:11:39  lr: 0.000246  loss: 0.8821 (1.8595)  loss_classifier: 0.2040 (0.3354)  loss_box_reg: 0.2140 (0.3609)  loss_mask: 0.2215 (0.5718)  loss_objectness: 0.0722 (0.3739)  loss_rpn_box_reg: 0.1192 (0.2175)  time: 3.8803  data: 3.5511  max mem: 3043\n",
      "241 (5, 1024, 1024) (1024, 1024, 3)\n",
      "242 (12, 1024, 1024) (1024, 1024, 3)\n",
      "243 (14, 1024, 1024) (1024, 1024, 3)\n",
      "244 (9, 1024, 1024) (1024, 1024, 3)\n",
      "245 (34, 1024, 1024) (1024, 1024, 3)\n",
      "246 (24, 1024, 1024) (1024, 1024, 3)\n",
      "247 (20, 1024, 1024) (1024, 1024, 3)\n",
      "248 (104, 1024, 1024) (1024, 1024, 3)\n",
      "249 (13, 1024, 1024) (1024, 1024, 3)\n",
      "250 (23, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [250/491]  eta: 0:11:11  lr: 0.000256  loss: 1.0892 (1.8209)  loss_classifier: 0.2010 (0.3304)  loss_box_reg: 0.1467 (0.3535)  loss_mask: 0.2215 (0.5571)  loss_objectness: 0.0949 (0.3627)  loss_rpn_box_reg: 0.0934 (0.2173)  time: 4.4915  data: 4.1604  max mem: 3043\n",
      "251 (26, 1024, 1024) (1024, 1024, 3)\n",
      "252 (58, 1024, 1024) (1024, 1024, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253 (38, 1024, 1024) (1024, 1024, 3)\n",
      "254 (46, 1024, 1024) (1024, 1024, 3)\n",
      "255 (21, 1024, 1024) (1024, 1024, 3)\n",
      "256 (59, 1024, 1024) (1024, 1024, 3)\n",
      "257 (19, 1024, 1024) (1024, 1024, 3)\n",
      "258 (23, 1024, 1024) (1024, 1024, 3)\n",
      "259 (6, 1024, 1024) (1024, 1024, 3)\n",
      "260 (35, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [260/491]  eta: 0:10:38  lr: 0.000267  loss: 1.1680 (1.7981)  loss_classifier: 0.2137 (0.3283)  loss_box_reg: 0.1779 (0.3482)  loss_mask: 0.2009 (0.5466)  loss_objectness: 0.1006 (0.3567)  loss_rpn_box_reg: 0.1472 (0.2182)  time: 2.4490  data: 2.1222  max mem: 3043\n",
      "261 (15, 1024, 1024) (1024, 1024, 3)\n",
      "262 (15, 1024, 1024) (1024, 1024, 3)\n",
      "263 (92, 1024, 1024) (1024, 1024, 3)\n",
      "264 (21, 1024, 1024) (1024, 1024, 3)\n",
      "265 (1, 1024, 1024) (1024, 1024, 3)\n",
      "266 (34, 1024, 1024) (1024, 1024, 3)\n",
      "267 (22, 1024, 1024) (1024, 1024, 3)\n",
      "268 (32, 1024, 1024) (1024, 1024, 3)\n",
      "269 (28, 1024, 1024) (1024, 1024, 3)\n",
      "270 (58, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [270/491]  eta: 0:10:17  lr: 0.000277  loss: 1.0475 (1.7684)  loss_classifier: 0.2438 (0.3230)  loss_box_reg: 0.1952 (0.3420)  loss_mask: 0.2297 (0.5374)  loss_objectness: 0.0838 (0.3476)  loss_rpn_box_reg: 0.2025 (0.2184)  time: 2.9019  data: 2.5814  max mem: 3043\n",
      "271 (16, 1024, 1024) (1024, 1024, 3)\n",
      "272 (10, 1024, 1024) (1024, 1024, 3)\n",
      "273 (8, 1024, 1024) (1024, 1024, 3)\n",
      "274 (3, 1024, 1024) (1024, 1024, 3)\n",
      "275 (7, 1024, 1024) (1024, 1024, 3)\n",
      "276 (77, 1024, 1024) (1024, 1024, 3)\n",
      "277 (35, 1024, 1024) (1024, 1024, 3)\n",
      "278 (12, 1024, 1024) (1024, 1024, 3)\n",
      "279 (25, 1024, 1024) (1024, 1024, 3)\n",
      "280 (93, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [280/491]  eta: 0:09:47  lr: 0.000287  loss: 0.9909 (1.7434)  loss_classifier: 0.2044 (0.3216)  loss_box_reg: 0.1969 (0.3374)  loss_mask: 0.2444 (0.5274)  loss_objectness: 0.0680 (0.3415)  loss_rpn_box_reg: 0.1314 (0.2155)  time: 3.0989  data: 2.7800  max mem: 3043\n",
      "281 (27, 1024, 1024) (1024, 1024, 3)\n",
      "282 (20, 1024, 1024) (1024, 1024, 3)\n",
      "283 (65, 1024, 1024) (1024, 1024, 3)\n",
      "284 (2, 1024, 1024) (1024, 1024, 3)\n",
      "285 (60, 1024, 1024) (1024, 1024, 3)\n",
      "286 (15, 1024, 1024) (1024, 1024, 3)\n",
      "287 (62, 1024, 1024) (1024, 1024, 3)\n",
      "288 (18, 1024, 1024) (1024, 1024, 3)\n",
      "289 (20, 1024, 1024) (1024, 1024, 3)\n",
      "290 (12, 1024, 1024) (1024, 1024, 3)\n",
      "Epoch: [0]  [290/491]  eta: 0:09:16  lr: 0.000297  loss: 0.8506 (1.7131)  loss_classifier: 0.1909 (0.3169)  loss_box_reg: 0.1911 (0.3309)  loss_mask: 0.2441 (0.5175)  loss_objectness: 0.0500 (0.3328)  loss_rpn_box_reg: 0.1314 (0.2149)  time: 2.3962  data: 2.0833  max mem: 3043\n",
      "291 (10, 1024, 1024) (1024, 1024, 3)\n",
      "292 (46, 1024, 1024) (1024, 1024, 3)\n",
      "293 (18, 1024, 1024) (1024, 1024, 3)\n",
      "294 (16, 1024, 1024) (1024, 1024, 3)\n",
      "295 (26, 1024, 1024) (1024, 1024, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2580b3e885c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m# train for one epoch, printing every 10 iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;31m# update the learning rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Adrien\\src\\nuclei_segmentation\\engine.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, data_loader, device, epoch, print_freq)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mlr_scheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarmup_lr_scheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarmup_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarmup_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetric_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_every\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Adrien\\src\\nuclei_segmentation\\utils.py\u001b[0m in \u001b[0;36mlog_every\u001b[1;34m(self, iterable, print_freq, header)\u001b[0m\n\u001b[0;32m    212\u001b[0m         ])\n\u001b[0;32m    213\u001b[0m         \u001b[0mMB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1024.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1024.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m             \u001b[0mdata_time\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autoscroring\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autoscroring\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autoscroring\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\autoscroring\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-acc9a7c5aa46>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, image_id)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m              \u001b[1;31m#multi_mask = np.sum(mask*np.arange(1, mask.shape[-1]+1), axis=-1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             temp_image, temp_mask = random_shift_scale_rotate_transform(image.copy(), masks.copy(),\n\u001b[0m\u001b[0;32m    109\u001b[0m                                                                          \u001b[0mshift_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.0625\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0625\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                                                                          rotate_limit=[-15, 15])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from engine import train_one_epoch\n",
    "import utils\n",
    "from config import DATASET_PATH\n",
    "import os.path as op\n",
    "\n",
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "\n",
    "train_path = op.join(DATASET_PATH,'stage1_train/')\n",
    "classes_csv = op.join(DATASET_PATH,'classes.csv')\n",
    "\n",
    "# Split the training set into training and validation\n",
    "train_list, val_list = train_validation_split(\n",
    "    train_path,classes_csv , seed=11, test_size=0.1)\n",
    "\n",
    "# initialize training dataset\n",
    "dataset_train = NucleiDataset()\n",
    "dataset_train.load_shapes(train_list, train_path,'train')\n",
    "dataset_train.prepare()\n",
    "\n",
    "# initialize validation dataset\n",
    "dataset_val = NucleiDataset()\n",
    "dataset_val.load_shapes(val_list, train_path,'val')\n",
    "dataset_val.prepare()\n",
    "\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train, batch_size=1, shuffle=False, num_workers=0,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_val, batch_size=1, shuffle=False, num_workers=0,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.0005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)\n",
    "\n",
    "# let's train it for 10 epochs\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "print(\"That's it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
